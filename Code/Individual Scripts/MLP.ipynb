{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) for multi-class softmax classification (Keras Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding= UTF-8\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fix random seed number\n",
    "np.random.seed(7)\n",
    "\n",
    "# Load the data\n",
    "X = np.load('feat.npy')\n",
    "y = np.load('label.npy').ravel() #Return a contiguous flattened array.\n",
    "\n",
    "number_of_features = len(X[1]) #This is variable with each run\n",
    "number_of_classes = 3\n",
    "\n",
    "# Sample data randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) #70% Train, 30% Test\n",
    "\n",
    "# Neural Network Architecture\n",
    "model = Sequential() # Define Sequential model\n",
    "\n",
    "# Using relu on the first two layers and softmax on the output layer\n",
    "\n",
    "# 1st Layer\n",
    "#N neurons, Number_Fatures-dimensional vectors\n",
    "model.add(Dense(512, input_dim=number_of_features, activation='relu')) #32, 64, 128, 256, 512, 1024\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd Layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 3rd Layer. Output 3 neurons corresponding the number of classes\n",
    "# The sigmoid function is used for the two-class logistic regression, \n",
    "# whereas the softmax function is used for the multiclass logistic regression \n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "# Model Compilation. Loss for multi-class classification problem\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = 'rmsprop'\n",
    "adam = 'adam'\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= rmsprop, #rmsprop better than sgd\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train-1, num_classes= number_of_classes) # Convert class vector into binary Matrix\n",
    "y_test = keras.utils.to_categorical(y_test-1, num_classes= number_of_classes)\n",
    "\n",
    "# Train and test\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=64) #batch 32, 64, 128, 256, 512\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Test score:', score\n",
    "print'Test accuracy:', acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 Conda2",
   "language": "python",
   "name": "anaconda2_py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
